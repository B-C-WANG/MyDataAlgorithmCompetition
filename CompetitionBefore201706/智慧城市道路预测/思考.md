## 原始数据分析：
- 道路数据：道路一共有131条，每条有长度和宽度，以及道路等级信息
- 另一张表给出了一段时间内各个道路的车辆平均旅行时间，每个时间段的长度为2分钟，尚不知这些时间是否连续相连，总共766万个数据，每一个数据有一个道路id，时间以及平均旅行时间。
- 另外一张表给出了道路之间相连的信息

## 思路：
- 首先最主要的车辆平均旅行时间需要进行处理：
- 方法1：按照道路id进行分类，每个id有所有的时间以及对应的time数据，按照时序处理每条道路，但是道路与道路之间会有相关关系，不太好处理
- 方法2：按照时间进行分类，将时间转变为帧，每一帧下有一个道路连通图，这个图上标识了所有的信息，根据这个图进行判断。或者，干脆就做出这个二维图，将拥堵程度用灰度大小表示，之后LSTM+卷积处理

## 准备尝试方法2
- 首先是按照时间进行排序，只有在时间排序有思路之后，才能进行道路树状图的绘制
- 关于其他内容，见代码中的注释





# 具体解题步骤：
**将源数据按照时间归类，每一个时间有132个道路信息，相当于将同字段列表合并**
**这样得到了每个时间下的132维度数据，将其视作“帧”处理**
**上面那只是一个“视频”，按照每个视频900帧，以及每个视频相当于上个视频向后滑动100帧来处理，数据量扩大8.9倍，得到了670多个900帧的视频**
**接着用前一个视频作为输入，后一个视频作为输出，建立ConvLSTM模型，预测最后900帧的视频**
- 卷积能够帮助找到节点关系，因而卷积核面积要大，这是为了能够让任意两个数据联系起来。LSTM主要是处理时间序列相关的。


# 核心思路
- 视频图像处理那么牛X的神经网络，也应该用在其他数据处理上

# 新的解题步骤
- **由于数据集是3个月的，但是实际上是根据最后一个月前两个小时的数据推算之后两个小时的数据，所以实际上数据集可以大大删减，并且将数据集划分成训练集和测试集，每一个月的前两个小时作为train，之后两个小时作为test，因为最终目的，就是根据最后一个月的前两个小时推测后面两个小时**
- **于是训练集变成了92 x 60 x 132 x 1，测试集变成了92 x 30 x 132 x 1**

- - 将60 x 132变成30 x 132，可以使用卷积，可以全连接，也可以将60或者30变成帧，然后使用132 x 1的图像进行ConvLSTM
- 但是在之后的过程中，我发现loss很难降下来，可能是参数过多难以训练，接着就是调整参数，如何降下loss，或者说，这样是需要正则化的？
- **此外，可能和reshape有关系，reshape可能需要reshape为(60, 92, 132)而不是(92, 60, 132)，因为首先是需要按照60数据进行划分的，于是就先重新划分，然后进行转置交换，至于有没有错，需要先print结果对比一下！**
- 之后，采用全局正则化方式，对所有数据进行正则化，先将数据reshape成二维以下，然后fit，存储正则化模型，进行正则化。选用的方式是将按照训练集的正则化方式进行正则化，之后测试集也会按照训练集的方法正则化，**即使之后正则化的方式改变，训练的模型应该也不会有太大变动**


